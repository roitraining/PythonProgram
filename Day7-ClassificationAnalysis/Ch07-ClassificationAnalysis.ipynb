{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DftlMhfXlhNI"
   },
   "source": [
    "## Combine the multiple files into one big CSV since we could not load a large file to GitHub. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U79c08g9lhNK"
   },
   "outputs": [],
   "source": [
    "! ./combine.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PCx-mtOzlhNP"
   },
   "source": [
    "### Read in a set of data and examine it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JYKsqCNglhNR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('CreditCardFraud.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jH3_XW7-IFNt",
    "outputId": "a6017840-b7b5-45f6-bdd4-4fc86b9fcd99"
   },
   "outputs": [],
   "source": [
    "print(df.shape, df.columns)\n",
    "train_size = .3\n",
    "test_size = .1\n",
    "\n",
    "display(df.head())\n",
    "print(df.isFraud.value_counts())\n",
    "print(df.type.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8mn1AZlPlhNW"
   },
   "source": [
    "### Keep the columns we want and change the type to code numbers instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lz3S1g6elhNX",
    "outputId": "2e717f05-3143-4651-c04c-d9d480d91f62"
   },
   "outputs": [],
   "source": [
    "columns = ['type', 'amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest', 'isFlaggedFraud', 'isFraud']\n",
    "df = df[columns]\n",
    "df.type = pd.Categorical(df.type).codes\n",
    "print(df.shape, df.columns)\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FKQQPPfflhNb"
   },
   "source": [
    "### Prepare train & test sets with desired columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oF8rjfsJlhNd",
    "outputId": "41a4c915-09ed-48fa-9632-cee08c124870"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing as pp\n",
    "dfNB = df\n",
    "trainNB_X, testNB_X, trainNB_Y, testNB_Y = train_test_split(dfNB[dfNB.columns[:-1]], dfNB.isFraud, \\\n",
    "                                        train_size = train_size, test_size = test_size, random_state = 1)\n",
    "print(testNB_Y.value_counts())\n",
    "print(trainNB_Y.value_counts()/trainNB_Y.count())\n",
    "print(testNB_Y.value_counts()/testNB_Y.count())\n",
    "display(trainNB_X.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kusVp-VnlhNg"
   },
   "source": [
    "## Create a Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iOMjiVP9lhNh",
    "outputId": "3f266268-517b-4bd2-8291-1f3f4febf5b1"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "modelNB = GaussianNB()\n",
    "modelNB.fit(trainNB_X, trainNB_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zIHKzxzrlhNm"
   },
   "source": [
    "### Examine the results of Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gu9BVBrrlhNo",
    "outputId": "58fe7f66-25d9-4f36-d788-8a59e0c79ed0"
   },
   "outputs": [],
   "source": [
    "def evaluate_predictions(test, pred, show_percent = True):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    length = len(test)\n",
    "    print(f'Test length = {length}')\n",
    "    print('\\nTest Values')\n",
    "    print(test.value_counts())\n",
    "    print('\\nPredicted Values')\n",
    "    #print(pred, type(pred))\n",
    "    print(pd.value_counts(pred))\n",
    "    print('\\n TP FP\\n FN TN')\n",
    "    cm = confusion_matrix(test, pred)\n",
    "    print(cm)\n",
    "\n",
    "    if show_percent:\n",
    "        import numpy as np\n",
    "        print('\\n PC FP\\n FN PW')\n",
    "        print(np.ndarray(shape = (2,2), buffer = np.array([100 *(cm[0][0] + cm[1][1])/length, \\\n",
    "           100 * cm[0][1]/length, 100 * cm[1][0]/length, 100 * (cm[1][0] + cm[0][1])/length])))\n",
    "\n",
    "          \n",
    "\n",
    "predNB_Y = modelNB.predict(testNB_X)\n",
    "evaluate_predictions(testNB_Y, predNB_Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K9_n3marlhNs"
   },
   "source": [
    "## Save a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M7Zr_8WklhNt"
   },
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "dump(modelNB, 'modelNB.joblib') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LJWFouMwlhNw"
   },
   "source": [
    "## Load a saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OMBMLAFOlhNy"
   },
   "outputs": [],
   "source": [
    "modelNB2 = load('modelNB.joblib')\n",
    "predNB_Y = modelNB2.predict(testNB_X)\n",
    "\n",
    "evaluate_predictions(testNB_Y, predNB_Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s5aWDH46IFOj"
   },
   "source": [
    "## LAB 1: ## \n",
    "\n",
    "### Do a similar set of steps as Naive Bayes but this time use a Decision Tree algorithm\n",
    "\n",
    "#### 1. Import the correct model to do DecisionTree\n",
    "#### 2. Create an instance of the model\n",
    "#### 3.\tTrain the model using the training sets\n",
    "#### 4. Explore the results\n",
    "\n",
    "<br>\n",
    "<details><summary>Click for <b>hint</b></summary>\n",
    "<p>\n",
    "<b>dir</b> sklearn.tree package to find the right name of the model class.\n",
    "<br>\n",
    "<b>help</b> the class name to explore the parameters. We can pass none in this case.\n",
    "<br>\n",
    "<b>fit</b> the empty model to train it.\n",
    "<br>\n",
    "Use the helper function to analyze the results. Which model did a better job?\n",
    "<br>\n",
    "<br>\n",
    "</p>\n",
    "</details>\n",
    "\n",
    "\n",
    "<details><summary>Click for <b>code</b></summary>\n",
    "<p>\n",
    "\n",
    "```python\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dfDT = df\n",
    "\n",
    "trainDT_X, testDT_X, trainDT_Y, testDT_Y = trainNB_X, testNB_X, trainNB_Y, testNB_Y\n",
    "\n",
    "modelDT = DecisionTreeClassifier()\n",
    "modelDT.fit(trainDT_X, trainDT_Y)\n",
    "predDT_Y = modelDT.predict(testDT_X)\n",
    "evaluate_predictions(testDT_Y, predDT_Y)\n",
    "\n",
    "```\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vnIYVeFzlhN3"
   },
   "source": [
    "## Train the Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vIMBWf5zlhN5"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import ???\n",
    "\n",
    "# copy the same datasets to the DT names just to keep a copy for the future\n",
    "dfDT, trainDT_X, testDT_X, trainDT_Y, testDT_Y = df, trainNB_X, testNB_X, trainNB_Y, testNB_Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n0kDC70rIFOu"
   },
   "source": [
    "## Decision Trees have another option to let you see what are the most important features influencing the decisions. The following helper function makes it easier to view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XB47qZLplhN-"
   },
   "outputs": [],
   "source": [
    "def important_features(model, columns):\n",
    "    return pd.DataFrame(model.feature_importances_, columns=['Importance'], index = columns).sort_values(['Importance'], ascending = False)\n",
    " \n",
    "print(important_features(modelDT, trainDT_X.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GFqHSW1nlhOd"
   },
   "source": [
    "## Prepare the data\n",
    "### Logistic Regression requires categorical data be dummy encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mRaTpXWMlhOe",
    "outputId": "47ac0203-9417-44a2-f022-6011e2fbddfa",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "def dummy_code(data, columns, drop_first = True):\n",
    "    for c in columns:\n",
    "        dummies = pd.get_dummies(data[c], prefix = c, drop_first = drop_first)\n",
    "        i = list(data.columns).index(c)\n",
    "        data = pd.concat([data.iloc[:,:i], dummies, data.iloc[:,i+1:]], axis = 1)\n",
    "    return data\n",
    "\n",
    "dfLR = dummy_code(df, ['type'], drop_first = True)\n",
    "trainLR_X, testLR_X, trainLR_Y, testLR_Y = train_test_split(dfLR.iloc[:,dfLR.columns != 'isFraud'], dfLR.isFraud, train_size = train_size, test_size = test_size, random_state = 1)\n",
    "\n",
    "print(testLR_X.columns)\n",
    "display(testLR_X.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_jje5i7zlhOn"
   },
   "source": [
    "## Create a Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4hcmFoNIlhOq",
    "outputId": "a0d5a963-27a6-49b4-ae47-26700e28d180"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "modelLR = LogisticRegression(multi_class='auto', solver='lbfgs')\n",
    "modelLR.fit(trainLR_X, trainLR_Y)\n",
    "print(modelLR.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eQBvfbCilhOt"
   },
   "source": [
    "## Examine the results of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O7gJdlFelhOu",
    "outputId": "1f2b2d5a-e8d1-47ee-ef49-588c53d2ac6f"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "predLR_Y = modelLR.predict(testLR_X)\n",
    "\n",
    "score = modelLR.score(testLR_X, testLR_Y)\n",
    "mse = np.mean((predLR_Y - testLR_Y)**2)\n",
    "print(score, mse, '\\n')\n",
    "\n",
    "evaluate_predictions(testLR_Y, predLR_Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GUPQBLvcIFPK"
   },
   "source": [
    "## Logistic regression has another option called predict_proba() that can be used to set a custom threshold rather than the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Hw_OIYSIFPM",
    "outputId": "e1e51a05-1aeb-445f-fe3a-95f8b5d1272f"
   },
   "outputs": [],
   "source": [
    "predLR_Y1 = modelLR.predict_proba(testLR_X)\n",
    "display(predLR_Y1)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "roc = roc_auc_score(testLR_Y, predLR_Y)\n",
    "fpr, tpr, x = roc_curve(testLR_Y, predLR_Y1[:,1])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr, tpr, label = 'AUC = ' + str(roc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mTgCGR1XlhOy"
   },
   "source": [
    "## Try Logistic Regression with different probability thresholds to change ratio of false negatives and positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5CcSOW6YlhOz",
    "outputId": "62ae9c91-dc3f-464f-b237-ecabf3fa2bd0"
   },
   "outputs": [],
   "source": [
    "predLR_Y = modelLR.predict_proba(testLR_X)\n",
    "print(predLR_Y[:10])\n",
    "print('Score', modelLR.score(testLR_X, testLR_Y))\n",
    "\n",
    "for threshold in range(10, 91, 10):\n",
    "    predLR_Y1 = np.where(predLR_Y[:,0] >= threshold/100, 0, 1)\n",
    "    mse = np.mean((predLR_Y1 - testLR_Y)**2)\n",
    "    print ('\\nTHRESHOLD', threshold, 'MSE', mse)\n",
    "\n",
    "    evaluate_predictions(testLR_Y, predLR_Y1, show_percent = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t2zNQoQblhO6"
   },
   "source": [
    "## Prepare the data for a Neural Network\n",
    "### This time you should not drop the first column when dummy encoding. Additionally, data works better if it is rescaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W28T7EjClhO7",
    "outputId": "d04f5a1f-102a-45e2-9669-6d1822fc52b8"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing as pp\n",
    "# rescale the data\n",
    "dfNN = dummy_code(df, ['type'], drop_first = False)\n",
    "print(dfNN.columns)\n",
    "dfNN[['amount',  'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']] /= dfNN[['amount',  'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']].max()\n",
    "trainNN_X, testNN_X, trainNN_Y, testNN_Y = train_test_split(dfNN.iloc[:,dfNN.columns != 'isFraud'], dfNN.isFraud, train_size = train_size, test_size = test_size, random_state = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tcfBRlA8lhPC"
   },
   "source": [
    "## Create a Neural Network model\n",
    "This is running very slow here so let's not do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0HnUlj-TlhPD",
    "outputId": "9e8664ce-b6ec-4c4e-eddd-47de42f41090"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "modelNN = MLPClassifier(hidden_layer_sizes = (5, 3, 2), activation = 'logistic')\n",
    "modelNN.fit(trainNN_X, trainNN_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eyo1DTHYlhPJ"
   },
   "source": [
    "## Examine the results of Neural Network predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0WD0s5Z0lhPL",
    "outputId": "36bf511e-3f0b-48eb-9acd-38d92e815950"
   },
   "outputs": [],
   "source": [
    "predNN_Y = modelNN.predict(testNN_X)\n",
    "\n",
    "evaluate_predictions(testNN_Y, predNN_Y, show_percent = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_SWOc1o2lhPO"
   },
   "source": [
    "## Create a SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QNuyggKylhPQ",
    "outputId": "460fec31-986e-4d3b-ad76-06adcf9549bd"
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "train_size = .03\n",
    "test_size = .01\n",
    "dfSVM = dfNN\n",
    "trainSVM_X, testSVM_X, trainSVM_Y, testSVM_Y = train_test_split(dfSVM.iloc[:,dfSVM.columns != 'isFraud'], dfSVM.isFraud, train_size = train_size, test_size = test_size)\n",
    "\n",
    "def do_SVM(kernel, gamma):\n",
    "    print (\"\\nKernel:\", kernel, \"Gamma:\", gamma)\n",
    "    modelSVM = svm.SVC(gamma = gamma,  kernel = kernel)\n",
    "    modelSVM.fit(trainSVM_X, trainSVM_Y)\n",
    "    print (modelSVM.score(testSVM_X, testSVM_Y))\n",
    "\n",
    "    predSVM_Y = modelSVM.predict(testSVM_X)\n",
    "    evaluate_predictions(testSVM_Y, predSVM_Y, show_percent = False)\n",
    "    \n",
    "do_SVM('linear', gamma='auto')\n",
    "\n",
    "for kernel in ['rbf', 'poly', 'sigmoid']:\n",
    "    for gamma in ['auto', 10, 100]:\n",
    "        if not (kernel == 'poly' and gamma == 100):\n",
    "           do_SVM(kernel, gamma)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dkLoTkrJIFPr"
   },
   "source": [
    "## Ensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZEVweEHXlhOB"
   },
   "source": [
    "## Create and train a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "To_f6JTWlhOC",
    "outputId": "8a56e0a6-2ec0-4a55-f146-e928dfb3c229"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "modelRF = RandomForestClassifier(n_estimators=10)\n",
    "trainRF_X, trainRF_Y, testRF_X, testRF_Y = trainDT_X, trainDT_Y, testDT_X, testDT_Y\n",
    "modelRF.fit(trainRF_X, trainRF_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lycJ3JJZlhOI"
   },
   "source": [
    "## Test the accuracy of the predictions and examine important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-4yKn4pklhOJ"
   },
   "outputs": [],
   "source": [
    "predRF_Y = modelRF.predict(testRF_X)\n",
    "from sklearn import metrics\n",
    "print (\"Accuracy:\",metrics.accuracy_score(testRF_Y, predRF_Y))\n",
    "\n",
    "cm = confusion_matrix(testRF_Y, predRF_Y)\n",
    "print (cm)\n",
    "\n",
    "import pandas as pd\n",
    "feature_imp = pd.Series(modelRF.feature_importances_,index=trainRF_X.columns).sort_values(ascending=False)\n",
    "print (feature_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Iqv4i89lhOM"
   },
   "source": [
    "## Visualize important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gLly66iulhON"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "# Creating a bar plot\n",
    "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "# Add labels to your graph\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-bGX1pYklhOR"
   },
   "source": [
    "## Try removing less important features and retrain it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TtPKVlDKlhOS"
   },
   "outputs": [],
   "source": [
    "newTrainRF_X = trainRF_X[['newbalanceDest', 'oldbalanceOrg', 'amount', 'oldbalanceDest']]\n",
    "newTestRF_X = testRF_X[['newbalanceDest', 'oldbalanceOrg', 'amount', 'oldbalanceDest']]\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "modelRF = RandomForestClassifier(n_estimators=10)\n",
    "modelRF.fit(newTrainRF_X, trainRF_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BhtCXClKlhOY"
   },
   "source": [
    "### In this case the accuracy did not go up, but in many cases it does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UhFbYZ2slhOa"
   },
   "outputs": [],
   "source": [
    "newpredRF_Y = modelRF.predict(newTestRF_X)\n",
    "from sklearn import metrics\n",
    "print (\"Accuracy:\",metrics.accuracy_score(testRF_Y, newpredRF_Y))\n",
    "cm = confusion_matrix(testRF_Y, newpredRF_Y)\n",
    "print (cm)\n",
    "\n",
    "import pandas as pd\n",
    "feature_imp = pd.Series(modelRF.feature_importances_,index=newTrainRF_X.columns).sort_values(ascending=False)\n",
    "print (feature_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UD7Ir1LfIFQQ"
   },
   "source": [
    "### Voting Classifier will run all the specified models and choose the result based on voting among the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lh0Dviv-lhPg",
    "outputId": "583d83e5-9532-4800-83db-e1171fbc0ac1"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "modelVC = VotingClassifier(estimators=[('dt', modelDT), ('nb', modelNB)], voting='hard')\n",
    "modelVC.fit(trainDT_X, trainDT_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ch74VXo6IFQV",
    "outputId": "9a322332-6f09-40ae-a3a9-487c93b94c10"
   },
   "outputs": [],
   "source": [
    "print(modelVC.score(testDT_X, testDT_Y))\n",
    "predVC_Y = modelVC.predict(testDT_X)\n",
    "evaluate_predictions(testDT_Y, predVC_Y, show_percent = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sVGjSV7VIFQZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "07-01-ClassificationAnalysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
