{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandasql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pandasql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandasql as ps\n",
    "from pandasql import sqldf\n",
    "pysqldf = lambda q: sqldf(q, globals())\n",
    "\n",
    "iris = pd.read_csv('../Day3-Pandas/iris-data-index-column.csv', index_col=0, header=0)\n",
    "display(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'select upper(Class) as Class, Sepal_Length * 10 as S_Length, Sepal_Width / 10 as S_Width from iris'\n",
    "\n",
    "iris2 = pysqldf(query)\n",
    "display(iris2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB 1: ## \n",
    "\n",
    "### There are also some built in sample datasets that can be used to play around with in pandasql\n",
    "\n",
    "#### 1.\tUse the meat DataFrame below, and find how many records have a null value for the broilers field \n",
    "#### 2.\tTry to do the same using standard pandas commands\n",
    "\n",
    "<br>\n",
    "<details><summary>Click for <b>hint</b></summary>\n",
    "<p>\n",
    "For pandasql use the name of the variable as a table name in the FROM clause\n",
    "<br>\n",
    "Use SQL SELECT COUNT and a null test in the WHERE clause\n",
    "<br>\n",
    "For standard Pandas, get the Series for the broilers column using [] notation\n",
    "<br>\n",
    "Use isnull() method to get a Series of True/False for the rows that are null\n",
    "<br>\n",
    "Use that to get just the rows from the DataFrame that are null\n",
    "<br>\n",
    "use the len() function to see how many there are\n",
    "<br>\n",
    "<br>\n",
    "</p>\n",
    "</details>\n",
    "\n",
    "\n",
    "<details><summary>Click for <b>code</b></summary>\n",
    "<p>\n",
    "\n",
    "```python\n",
    "import pandasql as ps\n",
    "from pandasql import sqldf\n",
    "pysqldf = lambda q: sqldf(q, globals())\n",
    "\n",
    "meat = ps.load_meat()\n",
    "#display(meat)\n",
    "\n",
    "print(pysqldf('select count(*) from meat where broilers is null'))\n",
    "\n",
    "print(len(meat['broilers'][meat['broilers'].isnull()]))\n",
    "\n",
    "```\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandasql as ps\n",
    "from pandasql import sqldf\n",
    "pysqldf = lambda q: sqldf(q, globals())\n",
    "\n",
    "meat = ps.load_meat()\n",
    "display(meat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NVB7MroPip3f"
   },
   "source": [
    "## Central Tendency\n",
    "Pandas is a module that contains the DataFrame object.\n",
    "Here we are looking at the three measures of central tendency and the count of how many objects in the DataFrame.\n",
    "Then we show each unique value and how many times it occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JyHWoJ4oip3i"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([9,10,10,11,11,11,12,12,12,13,13,13,13,14], columns=['Age'])\n",
    "\n",
    "print(\"Mean\", df.Age.mean(), \"Median\", df.Age.median(), \"Mode\", df.Age.mode()[0], \"Count\", df.Age.count())\n",
    "print(df.Age.value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB 2: ## \n",
    "\n",
    "### Find the three central tendencies for beef in the meat DataFrame\n",
    "<br>\n",
    "<details><summary>Click for <b>hint</b></summary>\n",
    "<p>\n",
    "Try to use . syntax and [] syntax as alternatives to get the beef column\n",
    "<br>\n",
    "Remember mode is trickier, try using both mode and value_counts to make sure you understand how to get the mode\n",
    "<br>\n",
    "Of the three central tendencies which makes the most sense to use in this case\n",
    "<br>\n",
    "<br>\n",
    "</p>\n",
    "</details>\n",
    "\n",
    "\n",
    "<details><summary>Click for <b>code</b></summary>\n",
    "<p>\n",
    "\n",
    "```python\n",
    "print(meat.beef.mean(), meat['beef'].median(), meat.beef.mode()[0])\n",
    "print(meat['beef'].mode())\n",
    "print(meat.beef.value_counts())\n",
    "\n",
    "```\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o_AhQBBCip3n"
   },
   "source": [
    "## Plotting\n",
    "We can visualize what the data looks like with a number of different plots.\n",
    "Boxplots are useful to see the big picture on a series of numbers.\n",
    "We can see min, max, mean, and the inter quartile range.\n",
    "\n",
    "## Box Plot\n",
    "Shows the minimum, maximum, mean, and inter quartile range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jAwMPJvOip3p"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mp\n",
    "from matplotlib import pyplot as plt\n",
    "plt.ylim(8,15)\n",
    "df.boxplot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CnwAuPdpip3v"
   },
   "source": [
    "## Histogram\n",
    "Good for looking at how many items fall within a range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I7w5iHx1ip3w"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "df = pd.DataFrame(np.random.rand(253, 1) * 254, columns=['col1'])\n",
    "df.hist(histtype='bar', ec='black')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5aiubz4pip30"
   },
   "source": [
    "## Bar Chart\n",
    "Useful for seeing how many items are in each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ixymtPR1ip31"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([('Male', 10),('Male', 11), ('Female', 11), ('Female', 12), ('Female', 12)], columns=['Gender','Age'])\n",
    "x = df.groupby('Gender').count()\n",
    "print(x)\n",
    "x.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB 3: ## \n",
    "\n",
    "### Create a boxplot to compare beef, veal and pork\n",
    "### Run a histogram on the same three\n",
    "<br>\n",
    "<details><summary>Click for <b>hint</b></summary>\n",
    "<p>\n",
    "Select the three columns from meat using the [[]] syntax \n",
    "<br>\n",
    "Run a boxplot method on the DataFrame of three columns\n",
    "<br>\n",
    "<br>\n",
    "</p>\n",
    "</details>\n",
    "\n",
    "\n",
    "<details><summary>Click for <b>code</b></summary>\n",
    "<p>\n",
    "\n",
    "```python\n",
    "%matplotlib inline\n",
    "somemeat = meat[['beef', 'veal', 'pork']]\n",
    "somemeat.boxplot()\n",
    "\n",
    "somemeat.hist(histtype='bar', ec='black')\n",
    "\n",
    "```\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "somemeat = meat[['beef', 'veal', 'pork']]\n",
    "somemeat.boxplot()\n",
    "\n",
    "somemeat.hist(histtype='bar', ec='black')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CDWOsr-Jip3-"
   },
   "source": [
    "## Replacing Null Values with the Central Tendency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SSCCCk8tip3_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "fatal = pd.read_csv('2012_Workplace_Fatalities_by_State.csv')\n",
    "print(fatal.columns)\n",
    "fatal.columns = ['State', 'NumberOfFatalities', 'RateOfFatalities', 'StateRank', 'NumberOfInjuries', 'InjuriesRate', 'PenaltiesAvg', 'PenaltiesRank', 'Inspectors', 'YearsToInspectEachWorkplaceOnce', 'StateFederal']\n",
    "print(fatal.PenaltiesRank.mean())\n",
    "print(fatal.PenaltiesRank[48:])\n",
    "print(fatal.PenaltiesRank[48:].isnull())\n",
    "fatal.PenaltiesRank = fatal.PenaltiesRank.fillna(fatal.PenaltiesRank.mean())\n",
    "print(fatal.PenaltiesRank[48:])\n",
    "fatal.dropna(axis = 0, inplace = True)\n",
    "print(fatal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB 4: ## \n",
    "\n",
    "### Calculate the central tendency for broilers\n",
    "### Replace the null values for broilers with that central tendency\n",
    "<br>\n",
    "<details><summary>Click for <b>hint</b></summary>\n",
    "<p>\n",
    "Use mean for the central tendency\n",
    "<br>\n",
    "Use fillna to replace the null values for broilers. Try it with inplace False first, then True to see the different syntax\n",
    "<br>\n",
    "<br>\n",
    "</p>\n",
    "</details>\n",
    "\n",
    "\n",
    "<details><summary>Click for <b>code</b></summary>\n",
    "<p>\n",
    "\n",
    "```python\n",
    "meat = ps.load_meat()\n",
    "broilersct = meat.broilers.mean()\n",
    "print(broilersct)\n",
    "display(meat)\n",
    "meat2 = meat.broilers.fillna(broilersct, inplace = False)\n",
    "display(meat)\n",
    "display(meat2)\n",
    "meat.broilers = meat2\n",
    "display(meat)\n",
    "\n",
    "meat = ps.load_meat()\n",
    "meat.broilers.fillna(meat.broilers.mean(), inplace = True)\n",
    "display(meat)\n",
    "```\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now suppose you want to do that for several columns. Let's use the apply function to run the fillna function on each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meat = ps.load_meat()\n",
    "cols = ['beef', 'veal', 'pork', 'lamb_and_mutton', 'broilers', 'other_chicken', 'turkey']\n",
    "meat[cols] = meat[cols].apply(lambda x : x.fillna(x.mean()))\n",
    "display(meat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AElshSLoip4C"
   },
   "source": [
    "## Add and Remove Columns to a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tZgoQuAPip4E"
   },
   "outputs": [],
   "source": [
    "print(fatal.columns)\n",
    "fatal.insert(11, 'ProgramType', pd.Categorical(fatal['StateFederal']).codes)\n",
    "print(fatal[['ProgramType', 'StateFederal']][:5])\n",
    "fatal.drop(['StateFederal'], axis=1, inplace=True)\n",
    "print(fatal.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RmrSFKVvip4H"
   },
   "source": [
    "## Change Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BtYUfU_eip4I"
   },
   "outputs": [],
   "source": [
    "print(fatal.NumberOfFatalities[48:])\n",
    "fatal.NumberOfFatalities = fatal.NumberOfFatalities.fillna(0).astype(int)\n",
    "print(fatal.NumberOfFatalities[48:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "toQi09Pwip4O"
   },
   "source": [
    "## Rescale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "umiQEHKEip4Q",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing as pp\n",
    "x = fatal.NumberOfFatalities.astype(float)\n",
    "print(x.mean(), x.std(), x.min(), x.max())\n",
    "print(x[10:15])\n",
    "print(pp.scale(x, with_mean = False, with_std = False)[10:15])\n",
    "print(pp.scale(x, with_mean = True, with_std = False)[10:15])\n",
    "print(pp.scale(x, with_mean = False, with_std = True)[10:15])\n",
    "print(pp.scale(x, with_mean = True, with_std = True)[10:15])\n",
    "print(pp.scale(x, with_mean = True, with_std = True)[10:15])\n",
    "\n",
    "r = pp.scale(x, with_mean = True, with_std = True)\n",
    "fatal.NumberOfFatalities = r\n",
    "print('rescaled', fatal.NumberOfFatalities[10:15])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB 5: ## \n",
    "\n",
    "### Right after the last lab, we used the apply function to replace null values for each column with the central tendency of that column. Using a similar technique, see if you can rescale those same columns centered around the mean and std.\n",
    "<br>\n",
    "<details><summary>Click for <b>hint</b></summary>\n",
    "<p>\n",
    "Use apply and a lambda to that uses pp.scale\n",
    "<br>\n",
    "<br>\n",
    "</p>\n",
    "</details>\n",
    "<details><summary>Click for <b>code</b></summary>\n",
    "<p>\n",
    "\n",
    "```python\n",
    "from sklearn import preprocessing as pp\n",
    "meat = ps.load_meat()\n",
    "cols = ['beef', 'veal', 'pork', 'lamb_and_mutton', 'broilers', 'other_chicken', 'turkey']\n",
    "meat[cols] = meat[cols].apply(lambda x : x.fillna(x.mean()))\n",
    "meat[cols] = meat[cols].apply(lambda x : pp.scale(x, with_mean = True, with_std = True))\n",
    "\n",
    "display(meat)\n",
    "```\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing as pp\n",
    "meat = ps.load_meat()\n",
    "cols = ['beef', 'veal', 'pork', 'lamb_and_mutton', 'broilers', 'other_chicken', 'turkey']\n",
    "meat[cols] = meat[cols].apply(lambda x : x.fillna(x.mean()))\n",
    "\n",
    "display(meat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eskMhUATip4T"
   },
   "source": [
    "## Concat Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tLd6Hr-9ip4U"
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame([('Male', 10),('Male', 11), ('Female', 11), ('Female', 12), ('Female', 12)], columns=['Gender','Age'])\n",
    "df2 = pd.DataFrame([('Male', 20),('Male', 21), ('Female', 21), ('Female', 22)], columns=['Gender','Age'])\n",
    "df = pd.concat([df1, df2])\n",
    "print(df)\n",
    "df3 = pd.DataFrame([('John', 'Smith'), ('Joe','Average'), ('Jane', 'Doe'), ('Jill', 'Hill')], columns = ['First', 'Last'])\n",
    "df = pd.concat([df1, df3], axis = 1)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TYqrzlTXip4X"
   },
   "source": [
    "## Merge or Join DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dYs3_7bfip4Z"
   },
   "outputs": [],
   "source": [
    "person_data = {\n",
    "        'id': ['1', '2', '3', '4', '5'],\n",
    "        'first_name': ['John', 'Sue', 'Jack', 'Alice', 'Joe'], \n",
    "        'last_name': ['Smith', 'Miller', 'Sprat', 'Wonderland', 'Blow']}\n",
    "df1 = pd.DataFrame(person_data, columns = ['id', 'first_name', 'last_name'])\n",
    "\n",
    "skill_data = {\n",
    "    'id' : ['1', '1', '2', '3', '3', '3', '5', '6'],\n",
    "    'skill' : ['C++', 'Java', 'Java', 'C++', 'Java', 'Python', 'Python', 'Java']\n",
    "}\n",
    "df2 = pd.DataFrame(skill_data, columns = ['id', 'skill'])\n",
    "\n",
    "print(pd.merge(df1, df2, on = 'id'))\n",
    "print(pd.merge(df1, df2, how = 'left' ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-D3AF-_Sip4c"
   },
   "source": [
    "## Convert Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Ox-xD2eip4e"
   },
   "outputs": [],
   "source": [
    "person_data = { 'id': ['1', '2', '3', '4', '5'],       \n",
    "     'first_name': ['John', 'Sue', 'Jack', 'Alice', 'Joe'],        \n",
    "     'status': ['Active', 'Active', 'Pending', 'Cancelled', 'Cancelled']}\n",
    "df1 = pd.DataFrame(person_data, columns = ['id', 'first_name', 'status'])\n",
    "print(df1)\n",
    "df1.status = pd.Categorical(df1.status).codes\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yy0hvVZRip4i"
   },
   "source": [
    "## Dummy Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nSsVjP39ip4j"
   },
   "outputs": [],
   "source": [
    "person_data = { 'id': ['1', '2', '3', '4', '5'],       \n",
    "     'first_name': ['John', 'Sue', 'Jack', 'Alice', 'Joe'],        \n",
    "     'status': ['Active', 'Active', 'Pending', 'Cancelled', 'Cancelled']}\n",
    "df1 = pd.DataFrame(person_data, columns = ['id', 'first_name', 'status'])\n",
    "print(df1)\n",
    "\n",
    "dummies = pd.get_dummies(df1.status, drop_first = True)\n",
    "df2 = pd.concat([df1[['id','first_name']], dummies], axis = 1)\n",
    "print(df2)\n",
    "\n",
    "dummies = pd.get_dummies(df1.status, drop_first = False)\n",
    "df3 = pd.concat([df1[['id','first_name']], dummies], axis = 1)\n",
    "print(df3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ES7gmlHgip4m"
   },
   "source": [
    "## Split Data into Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2fF8HX2gip4n"
   },
   "outputs": [],
   "source": [
    "print ('Split 1')\n",
    "train = fatal.sample(frac=0.8,random_state=200)\n",
    "test = fatal[~fatal.index.isin(train.index)]\n",
    "x0 = fatal.ProgramType\n",
    "x1 = train.ProgramType\n",
    "x2 = test.ProgramType\n",
    "\n",
    "print(x0.value_counts()/x0.count())\n",
    "print(x1.value_counts()/x1.count())\n",
    "print(x2.value_counts()/x2.count())\n",
    "print(fatal.shape, train.shape, test.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "print ('Split 2')\n",
    "train, test = train_test_split(fatal, test_size=0.2)\n",
    "x0 = fatal.ProgramType\n",
    "x1 = train.ProgramType\n",
    "x2 = test.ProgramType\n",
    "print(x0.value_counts()/x0.count())\n",
    "print(x1.value_counts()/x1.count())\n",
    "print(x2.value_counts()/x2.count())\n",
    "print(fatal.shape, train.shape, test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB 6: ## \n",
    "\n",
    "### Split the meat DataFrame into a 70/30 split\n",
    "<br>\n",
    "<details><summary>Click for <b>hint</b></summary>\n",
    "<p>\n",
    "Use train_test_split, it's way easier\n",
    "<br>\n",
    "<br>\n",
    "</p>\n",
    "</details>\n",
    "<details><summary>Click for <b>code</b></summary>\n",
    "<p>\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "meatTrain, meatTest = train_test_split(meat, test_size = 0.3)\n",
    "print(len(meatTrain), len(meatTest))\n",
    "```\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z_4kfwZeip4s"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "DIR = 'text'\n",
    "\n",
    "def corpus_from_dir(folder):\n",
    "    import os\n",
    "    ret = dict(docs = [open(os.path.join(folder,f)).read() for f in os.listdir(folder)],\n",
    "               ColNames = map(lambda x: x.split('.')[0], os.listdir(folder)))\n",
    "    return ret\n",
    "\n",
    "def tdm_df(docs, colNames = None, **kwargs):\n",
    "\n",
    "    #initialize the  vectorizer\n",
    "    vectorizer = CountVectorizer(**kwargs)\n",
    "    x1 = vectorizer.fit_transform(docs)\n",
    "    #create dataFrame\n",
    "    df = pd.DataFrame(x1.toarray().transpose(), index = vectorizer.get_feature_names())\n",
    "    if colNames is not None:\n",
    "        df.columns = colNames\n",
    "\n",
    "    return df\n",
    "\n",
    "corpus = corpus_from_dir(DIR)\n",
    "print(corpus)\n",
    "df = tdm_df(docs = corpus['docs'], colNames = corpus['ColNames'], stop_words = 'english')  \n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework: ## \n",
    "\n",
    "### Load the sales.csv file found in Day4\n",
    "### Replace the nulls with the means and rescale the numeric columns \n",
    "### Add a column for a numeric encoded version of color\n",
    "### Add a series of dummy coded columns for color\n",
    "<br>\n",
    "<details><summary>Click for <b>hint</b></summary>\n",
    "<p>\n",
    "Import the correct package to do rescaling\n",
    "<br>\n",
    "Remember to add a new column you can't use property or dot syntax to refer to a column\n",
    "<br>\n",
    "Remember to add Dummy Coded values you are adding more than one column so you need another method to add them to the DataFrame\n",
    "<br>\n",
    "<br>\n",
    "</p>\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sales = pd.read_csv('sales.csv', index_col=0, header=0)\n",
    "#display(sales)\n",
    "\n",
    "from sklearn import preprocessing as pp\n",
    "cols = ['cost', 'sales']\n",
    "sales[cols] = sales[cols].apply(lambda x : x.fillna(x.mean()))\n",
    "sales[cols] = sales[cols].apply(lambda x : pp.scale(x, with_mean = True, with_std = True))\n",
    "sales['colorcode'] = pd.Categorical(sales.color).codes\n",
    "dummies = pd.get_dummies(sales.color, drop_first = False)\n",
    "sales = pd.concat([sales, dummies], axis = 1)\n",
    "display(sales)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "04-01-DataPreparation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
